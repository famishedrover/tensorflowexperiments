{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/train-images-idx3-ubyte.gz\n",
      "Extracting data/MNIST/train-labels-idx1-ubyte.gz\n",
      "Extracting data/MNIST/t10k-images-idx3-ubyte.gz\n",
      "Extracting data/MNIST/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "data = input_data.read_data_sets('data/MNIST',one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data.test.cls = np.argmax(data.test.labels,axis=1)\n",
    "data.validation.cls = np.argmax(data.validation.labels,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# combining train and validation set\n",
    "combined_images = np.concatenate([data.train.images,data.validation.images])\n",
    "combined_labels = np.concatenate([data.train.labels,data.validation.labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(60000, 10)\n"
     ]
    }
   ],
   "source": [
    "print (combined_images.shape)\n",
    "print (combined_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "combined_size = len(combined_images)\n",
    "train_size = int(0.8*combined_size)\n",
    "validation_size = combined_size-train_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def random_training_set():\n",
    "    idx = np.random.permutation(combined_size)\n",
    "    idx_train = idx[:train_size]\n",
    "    idx_validation = idx[train_size:]\n",
    "    \n",
    "    x_train = combined_images[idx_train,:]\n",
    "    y_train = combined_labels[idx_train,:]\n",
    "    \n",
    "    x_validation = combined_images[idx_validation,:]\n",
    "    y_validation = combined_labels[idx_validation,:]\n",
    "    \n",
    "    return x_train,y_train , x_validation, y_validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_size = 28\n",
    "img_size_flat = img_size*img_size\n",
    "img_shape = (img_size,img_size)\n",
    "num_channels = 1\n",
    "num_classes = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODEL INPUTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32,shape=[None,img_size_flat],name='x')\n",
    "x_image = tf.reshape(x,[-1,img_size,img_size,num_channels])\n",
    "\n",
    "y_true = tf.placeholder(tf.float32,shape=[None,num_classes],name='y')\n",
    "y_true_cls = tf.arg_max(y_true,dimension=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODEL ARCHITECTURE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "net = x_image\n",
    "net = tf.layers.conv2d(inputs=net,name='layer_conv1',padding='same',filters=16,kernel_size=5,activation=tf.nn.relu)\n",
    "net = tf.layers.max_pooling2d(inputs = net,pool_size=2,strides=2)\n",
    "net = tf.layers.conv2d(inputs=net,name='layer_conv2',padding='same',filters=36,kernel_size=5,activation=tf.nn.relu)\n",
    "net = tf.layers.max_pooling2d(inputs=net,pool_size=2,strides=2)\n",
    "net = tf.contrib.layers.flatten(net)\n",
    "net = tf.layers.dense(inputs=net,units=128,activation=tf.nn.relu)\n",
    "net = tf.layers.dense(inputs=net,units=num_classes,activation=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logits = net\n",
    "y_pred = tf.nn.softmax(logits)\n",
    "y_pred_cls = tf.arg_max(y_pred,dimension=1)\n",
    "\n",
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits=logits,labels=y_true)\n",
    "loss = tf.reduce_mean(cross_entropy)\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=1e-4).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "correct_prediction = tf.equal(y_true_cls,y_pred_cls)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction,tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "saver = tf.train.Saver(max_to_keep=100)\n",
    "def get_save_path(net_number):\n",
    "    return 'checkpoints_ensemble_gpu/network'+str(net_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_batch_size = 64\n",
    "def random_batch(x_train,y_train):\n",
    "    num_images = len(x_train)\n",
    "    idx = np.random.choice(num_images,size= train_batch_size , replace=False)\n",
    "    x_batch = x_train[idx,:]\n",
    "    y_batch = y_train[idx,:]\n",
    "    return x_batch,y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def optimize(num_iterations,x_train,y_train):\n",
    "    start_time = time.time()\n",
    "    for i in range(num_iterations) :\n",
    "        x_batch,y_true_batch = random_batch(x_train,y_train)\n",
    "        feed_dict = {x:x_batch,y_true:y_true_batch}\n",
    "        session.run(optimizer,feed_dict=feed_dict)\n",
    "        if i%100 == 0 :\n",
    "            acc = session.run(accuracy,feed_dict=feed_dict)\n",
    "            print ('Iter {0:>6} Training Accuracy {1}'.format(i+1,acc))\n",
    "    end_time = time.time()\n",
    "    print ('Time Usage:',round(end_time-start_time,3),' seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF SESSION "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "session = tf.Session()\n",
    "def init_variables():\n",
    "    session.run(tf.global_variables_initializer())\n",
    "init_variables()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ENSEMBLE OF NETWORKS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_networks= 5\n",
    "num_iterations = 4000\n",
    "# keeping num_iterations small for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Network0\n",
      "Iter      1 Training Accuracy 0.171875\n",
      "Iter    101 Training Accuracy 0.734375\n",
      "Iter    201 Training Accuracy 0.890625\n",
      "Iter    301 Training Accuracy 0.953125\n",
      "Iter    401 Training Accuracy 0.9375\n",
      "Iter    501 Training Accuracy 0.921875\n",
      "Iter    601 Training Accuracy 0.96875\n",
      "Iter    701 Training Accuracy 0.90625\n",
      "Iter    801 Training Accuracy 0.90625\n",
      "Iter    901 Training Accuracy 0.90625\n",
      "Iter   1001 Training Accuracy 0.984375\n",
      "Iter   1101 Training Accuracy 0.953125\n",
      "Iter   1201 Training Accuracy 0.9375\n",
      "Iter   1301 Training Accuracy 0.9375\n",
      "Iter   1401 Training Accuracy 0.984375\n",
      "Iter   1501 Training Accuracy 0.96875\n",
      "Iter   1601 Training Accuracy 0.984375\n",
      "Iter   1701 Training Accuracy 0.984375\n",
      "Iter   1801 Training Accuracy 0.96875\n",
      "Iter   1901 Training Accuracy 0.984375\n",
      "Iter   2001 Training Accuracy 0.984375\n",
      "Iter   2101 Training Accuracy 0.953125\n",
      "Iter   2201 Training Accuracy 0.984375\n",
      "Iter   2301 Training Accuracy 0.96875\n",
      "Iter   2401 Training Accuracy 1.0\n",
      "Iter   2501 Training Accuracy 1.0\n",
      "Iter   2601 Training Accuracy 0.984375\n",
      "Iter   2701 Training Accuracy 0.9375\n",
      "Iter   2801 Training Accuracy 0.953125\n",
      "Iter   2901 Training Accuracy 0.96875\n",
      "Iter   3001 Training Accuracy 0.96875\n",
      "Iter   3101 Training Accuracy 0.984375\n",
      "Iter   3201 Training Accuracy 0.984375\n",
      "Iter   3301 Training Accuracy 0.96875\n",
      "Iter   3401 Training Accuracy 1.0\n",
      "Iter   3501 Training Accuracy 1.0\n",
      "Iter   3601 Training Accuracy 0.96875\n",
      "Iter   3701 Training Accuracy 0.984375\n",
      "Iter   3801 Training Accuracy 0.984375\n",
      "Iter   3901 Training Accuracy 0.96875\n",
      "Time Usage: 29.714  seconds\n",
      "\n",
      "Neural Network1\n",
      "Iter      1 Training Accuracy 0.09375\n",
      "Iter    101 Training Accuracy 0.859375\n",
      "Iter    201 Training Accuracy 0.890625\n",
      "Iter    301 Training Accuracy 0.859375\n",
      "Iter    401 Training Accuracy 0.9375\n",
      "Iter    501 Training Accuracy 0.953125\n",
      "Iter    601 Training Accuracy 0.921875\n",
      "Iter    701 Training Accuracy 0.953125\n",
      "Iter    801 Training Accuracy 0.96875\n",
      "Iter    901 Training Accuracy 0.9375\n",
      "Iter   1001 Training Accuracy 1.0\n",
      "Iter   1101 Training Accuracy 0.96875\n",
      "Iter   1201 Training Accuracy 0.9375\n",
      "Iter   1301 Training Accuracy 0.96875\n",
      "Iter   1401 Training Accuracy 0.9375\n",
      "Iter   1501 Training Accuracy 0.9375\n",
      "Iter   1601 Training Accuracy 0.9375\n",
      "Iter   1701 Training Accuracy 1.0\n",
      "Iter   1801 Training Accuracy 0.96875\n",
      "Iter   1901 Training Accuracy 0.984375\n",
      "Iter   2001 Training Accuracy 0.96875\n",
      "Iter   2101 Training Accuracy 0.96875\n",
      "Iter   2201 Training Accuracy 0.984375\n",
      "Iter   2301 Training Accuracy 0.96875\n",
      "Iter   2401 Training Accuracy 0.984375\n",
      "Iter   2501 Training Accuracy 1.0\n",
      "Iter   2601 Training Accuracy 0.96875\n",
      "Iter   2701 Training Accuracy 0.984375\n",
      "Iter   2801 Training Accuracy 0.953125\n",
      "Iter   2901 Training Accuracy 0.96875\n",
      "Iter   3001 Training Accuracy 0.96875\n",
      "Iter   3101 Training Accuracy 0.984375\n",
      "Iter   3201 Training Accuracy 0.953125\n",
      "Iter   3301 Training Accuracy 1.0\n",
      "Iter   3401 Training Accuracy 0.96875\n",
      "Iter   3501 Training Accuracy 0.953125\n",
      "Iter   3601 Training Accuracy 1.0\n",
      "Iter   3701 Training Accuracy 0.96875\n",
      "Iter   3801 Training Accuracy 1.0\n",
      "Iter   3901 Training Accuracy 0.984375\n",
      "Time Usage: 29.291  seconds\n",
      "\n",
      "Neural Network2\n",
      "Iter      1 Training Accuracy 0.140625\n",
      "Iter    101 Training Accuracy 0.8125\n",
      "Iter    201 Training Accuracy 0.890625\n",
      "Iter    301 Training Accuracy 0.890625\n",
      "Iter    401 Training Accuracy 0.875\n",
      "Iter    501 Training Accuracy 0.921875\n",
      "Iter    601 Training Accuracy 0.90625\n",
      "Iter    701 Training Accuracy 0.953125\n",
      "Iter    801 Training Accuracy 0.953125\n",
      "Iter    901 Training Accuracy 0.96875\n",
      "Iter   1001 Training Accuracy 0.984375\n",
      "Iter   1101 Training Accuracy 0.984375\n",
      "Iter   1201 Training Accuracy 0.953125\n",
      "Iter   1301 Training Accuracy 0.984375\n",
      "Iter   1401 Training Accuracy 0.953125\n",
      "Iter   1501 Training Accuracy 0.96875\n",
      "Iter   1601 Training Accuracy 0.984375\n",
      "Iter   1701 Training Accuracy 0.953125\n",
      "Iter   1801 Training Accuracy 0.953125\n",
      "Iter   1901 Training Accuracy 0.984375\n",
      "Iter   2001 Training Accuracy 0.96875\n",
      "Iter   2101 Training Accuracy 0.96875\n",
      "Iter   2201 Training Accuracy 0.984375\n",
      "Iter   2301 Training Accuracy 1.0\n",
      "Iter   2401 Training Accuracy 0.953125\n",
      "Iter   2501 Training Accuracy 0.921875\n",
      "Iter   2601 Training Accuracy 0.96875\n",
      "Iter   2701 Training Accuracy 0.984375\n",
      "Iter   2801 Training Accuracy 0.96875\n",
      "Iter   2901 Training Accuracy 0.96875\n",
      "Iter   3001 Training Accuracy 0.9375\n",
      "Iter   3101 Training Accuracy 0.984375\n",
      "Iter   3201 Training Accuracy 0.96875\n",
      "Iter   3301 Training Accuracy 0.984375\n",
      "Iter   3401 Training Accuracy 0.953125\n",
      "Iter   3501 Training Accuracy 0.9375\n",
      "Iter   3601 Training Accuracy 0.96875\n",
      "Iter   3701 Training Accuracy 0.984375\n",
      "Iter   3801 Training Accuracy 0.984375\n",
      "Iter   3901 Training Accuracy 0.984375\n",
      "Time Usage: 29.274  seconds\n",
      "\n",
      "Neural Network3\n",
      "Iter      1 Training Accuracy 0.21875\n",
      "Iter    101 Training Accuracy 0.765625\n",
      "Iter    201 Training Accuracy 0.9375\n",
      "Iter    301 Training Accuracy 0.9375\n",
      "Iter    401 Training Accuracy 0.890625\n",
      "Iter    501 Training Accuracy 0.96875\n",
      "Iter    601 Training Accuracy 0.96875\n",
      "Iter    701 Training Accuracy 0.921875\n",
      "Iter    801 Training Accuracy 1.0\n",
      "Iter    901 Training Accuracy 0.96875\n",
      "Iter   1001 Training Accuracy 0.921875\n",
      "Iter   1101 Training Accuracy 0.921875\n",
      "Iter   1201 Training Accuracy 0.953125\n",
      "Iter   1301 Training Accuracy 0.984375\n",
      "Iter   1401 Training Accuracy 1.0\n",
      "Iter   1501 Training Accuracy 0.953125\n",
      "Iter   1601 Training Accuracy 0.96875\n",
      "Iter   1701 Training Accuracy 0.984375\n",
      "Iter   1801 Training Accuracy 0.96875\n",
      "Iter   1901 Training Accuracy 0.984375\n",
      "Iter   2001 Training Accuracy 0.984375\n",
      "Iter   2101 Training Accuracy 0.96875\n",
      "Iter   2201 Training Accuracy 0.984375\n",
      "Iter   2301 Training Accuracy 0.953125\n",
      "Iter   2401 Training Accuracy 0.984375\n",
      "Iter   2501 Training Accuracy 0.953125\n",
      "Iter   2601 Training Accuracy 0.984375\n",
      "Iter   2701 Training Accuracy 0.984375\n",
      "Iter   2801 Training Accuracy 1.0\n",
      "Iter   2901 Training Accuracy 1.0\n",
      "Iter   3001 Training Accuracy 0.96875\n",
      "Iter   3101 Training Accuracy 0.984375\n",
      "Iter   3201 Training Accuracy 0.96875\n",
      "Iter   3301 Training Accuracy 0.984375\n",
      "Iter   3401 Training Accuracy 0.984375\n",
      "Iter   3501 Training Accuracy 1.0\n",
      "Iter   3601 Training Accuracy 0.984375\n",
      "Iter   3701 Training Accuracy 0.984375\n",
      "Iter   3801 Training Accuracy 1.0\n",
      "Iter   3901 Training Accuracy 0.984375\n",
      "Time Usage: 29.326  seconds\n",
      "\n",
      "Neural Network4\n",
      "Iter      1 Training Accuracy 0.125\n",
      "Iter    101 Training Accuracy 0.8125\n",
      "Iter    201 Training Accuracy 0.8125\n",
      "Iter    301 Training Accuracy 0.90625\n",
      "Iter    401 Training Accuracy 0.9375\n",
      "Iter    501 Training Accuracy 0.875\n",
      "Iter    601 Training Accuracy 0.953125\n",
      "Iter    701 Training Accuracy 0.953125\n",
      "Iter    801 Training Accuracy 0.953125\n",
      "Iter    901 Training Accuracy 0.984375\n",
      "Iter   1001 Training Accuracy 0.984375\n",
      "Iter   1101 Training Accuracy 0.9375\n",
      "Iter   1201 Training Accuracy 0.921875\n",
      "Iter   1301 Training Accuracy 1.0\n",
      "Iter   1401 Training Accuracy 0.953125\n",
      "Iter   1501 Training Accuracy 0.9375\n",
      "Iter   1601 Training Accuracy 0.984375\n",
      "Iter   1701 Training Accuracy 0.96875\n",
      "Iter   1801 Training Accuracy 0.96875\n",
      "Iter   1901 Training Accuracy 0.953125\n",
      "Iter   2001 Training Accuracy 0.984375\n",
      "Iter   2101 Training Accuracy 0.984375\n",
      "Iter   2201 Training Accuracy 0.953125\n",
      "Iter   2301 Training Accuracy 0.96875\n",
      "Iter   2401 Training Accuracy 0.9375\n",
      "Iter   2501 Training Accuracy 1.0\n",
      "Iter   2601 Training Accuracy 0.984375\n",
      "Iter   2701 Training Accuracy 0.96875\n",
      "Iter   2801 Training Accuracy 1.0\n",
      "Iter   2901 Training Accuracy 0.984375\n",
      "Iter   3001 Training Accuracy 1.0\n",
      "Iter   3101 Training Accuracy 1.0\n",
      "Iter   3201 Training Accuracy 0.96875\n",
      "Iter   3301 Training Accuracy 0.953125\n",
      "Iter   3401 Training Accuracy 0.96875\n",
      "Iter   3501 Training Accuracy 0.96875\n",
      "Iter   3601 Training Accuracy 0.984375\n",
      "Iter   3701 Training Accuracy 1.0\n",
      "Iter   3801 Training Accuracy 0.984375\n",
      "Iter   3901 Training Accuracy 1.0\n",
      "Time Usage: 29.33  seconds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if True :\n",
    "#     for each NN\n",
    "    for i in range(num_networks):\n",
    "        print ('Neural Network{0}'.format(i))\n",
    "        x_train,y_train,_,_ = random_training_set()\n",
    "        session.run(tf.global_variables_initializer())\n",
    "        \n",
    "        optimize(num_iterations,x_train=x_train,y_train=y_train)\n",
    "        saver.save(sess = session,save_path=get_save_path(i))\n",
    "        print ('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HELPER FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "def predict_label(images) :\n",
    "    num_images = len(images)\n",
    "    pred_labels = np.zeros(shape=(num_images,num_classes),dtype=np.float)\n",
    "    i=0\n",
    "    while(i<num_images):\n",
    "        j=min(i+batch_size,num_images)\n",
    "        feed_dict={x:images[i:j,:]}\n",
    "        \n",
    "        pred_labels[i:j] = session.run(y_pred,feed_dict=feed_dict)\n",
    "        i=j\n",
    "    return pred_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def correct_prediction(images,labels,cls_true):\n",
    "    pred_labels = predict_label(images)\n",
    "    cls_pred = np.argmax(pred_labels,axis=1)\n",
    "    \n",
    "    correct = (cls_pred==cls_true)\n",
    "    return correct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CORRECT - test & val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_correct():\n",
    "    return correct_prediction(images = data.test.images,\n",
    "                              labels = data.test.labels,\n",
    "                              cls_true=data.test.cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def validation_correct():\n",
    "    return correct_prediction(images = data.validation.images,\n",
    "                             labels = data.validation.labels,\n",
    "                             cls_true = data.validation.cls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  ACCURACY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def classification_accuracy(correct):\n",
    "    return correct.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_accuracy():\n",
    "    correct = test_correct()\n",
    "    return classification_accuracy(correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def validation_accuracy():\n",
    "    correct = validation_correct()\n",
    "    return classification_accuracy(correct)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RESULT ENSEMBLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ensemble_predictions():\n",
    "#     for each NN\n",
    "    pred_labels =[]\n",
    "    test_accuracies = []\n",
    "    val_accuracies = []\n",
    "    \n",
    "    for i in range(num_networks):\n",
    "        saver.restore(sess=session,save_path=get_save_path(i))\n",
    "        test_acc = test_accuracy()\n",
    "        val_acc = validation_accuracy()\n",
    "        test_accuracies.append(test_acc)\n",
    "        val_accuracies.append(val_acc)\n",
    "        print (\"Network: {0}, Accuracy Validation: {1:.4f}, Test: {2:.4f}\".format(i, val_acc, test_acc))\n",
    "        pred = predict_label(images=data.test.images)\n",
    "        pred_labels.append(pred)\n",
    "        \n",
    "    return np.array(pred_labels),np.array(test_accuracies),np.array(val_accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from checkpoints_ensemble/network0\n",
      "Network: 0, Accuracy Validation: 0.9854, Test: 0.9820\n",
      "INFO:tensorflow:Restoring parameters from checkpoints_ensemble/network1\n",
      "Network: 1, Accuracy Validation: 0.9828, Test: 0.9811\n",
      "INFO:tensorflow:Restoring parameters from checkpoints_ensemble/network2\n",
      "Network: 2, Accuracy Validation: 0.9846, Test: 0.9811\n",
      "INFO:tensorflow:Restoring parameters from checkpoints_ensemble/network3\n",
      "Network: 3, Accuracy Validation: 0.9810, Test: 0.9819\n",
      "INFO:tensorflow:Restoring parameters from checkpoints_ensemble/network4\n",
      "Network: 4, Accuracy Validation: 0.9822, Test: 0.9789\n"
     ]
    }
   ],
   "source": [
    "pred_labels, test_accuracies, val_accuracies = ensemble_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean test accuracy: 0.9810\n",
      "Min test accuracy:  0.9789\n",
      "Max test accuracy:  0.9820\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean test accuracy: {0:.4f}\".format(np.mean(test_accuracies)))\n",
    "print(\"Min test accuracy:  {0:.4f}\".format(np.min(test_accuracies)))\n",
    "print(\"Max test accuracy:  {0:.4f}\".format(np.max(test_accuracies)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 10000, 10)\n"
     ]
    }
   ],
   "source": [
    "print (pred_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ENSEMBLE PREDICTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 10)\n"
     ]
    }
   ],
   "source": [
    "ensemble_pred_labels = np.mean(pred_labels, axis=0)\n",
    "print (ensemble_pred_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "ensemble_cls_pred = np.argmax(ensemble_pred_labels, axis=1)\n",
    "print (ensemble_cls_pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ensemble_correct = (ensemble_cls_pred == data.test.cls)\n",
    "ensemble_incorrect = np.logical_not(ensemble_correct)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BEST NETWORK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.982   0.9811  0.9811  0.9819  0.9789]\n"
     ]
    }
   ],
   "source": [
    "print (test_accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Network: 0\n",
      "Test Accuracy of Best Network: 0.982\n"
     ]
    }
   ],
   "source": [
    "best_net = np.argmax(test_accuracies)\n",
    "print ('Best Network:',best_net)\n",
    "print ('Test Accuracy of Best Network:',test_accuracies[best_net])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best_net_pred_labels = pred_labels[best_net, :, :]\n",
    "best_net_cls_pred = np.argmax(best_net_pred_labels, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best_net_correct = (best_net_cls_pred == data.test.cls)\n",
    "best_net_incorrect = np.logical_not(best_net_correct)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## COMPARISON OF Ensemble & BestNetwork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Images Correctly Classified by Ensemble    : 9840\n",
      "Number of Images Correctly Classified by BestNetwork : 9820\n"
     ]
    }
   ],
   "source": [
    "print ('Number of Images Correctly Classified by Ensemble    :',np.sum(ensemble_correct))\n",
    "print ('Number of Images Correctly Classified by BestNetwork :',np.sum(best_net_correct))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54\n"
     ]
    }
   ],
   "source": [
    "ensemble_better = np.logical_and(best_net_incorrect,ensemble_correct)\n",
    "print (ensemble_better.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34\n"
     ]
    }
   ],
   "source": [
    "best_net_better = np.logical_and(best_net_correct,ensemble_incorrect)\n",
    "print (best_net_better.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
